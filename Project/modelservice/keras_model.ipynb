{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/pawelurbanowicz/master-thesis/data/'\n",
    "\n",
    "train_identity = pd.read_csv(f'{folder_path}train_identity.csv')\n",
    "train_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\n",
    "\n",
    "# train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "train = train_transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (590540, 394)\n"
     ]
    }
   ],
   "source": [
    "print('train: ', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[3 rows x 394 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transaction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>id_01</th>\n",
       "      <th>id_02</th>\n",
       "      <th>id_03</th>\n",
       "      <th>id_04</th>\n",
       "      <th>id_05</th>\n",
       "      <th>id_06</th>\n",
       "      <th>id_07</th>\n",
       "      <th>id_08</th>\n",
       "      <th>id_09</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987008</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>98945.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile safari 11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1334x750</td>\n",
       "      <td>match_status:1</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987010</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>191631.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>chrome 62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  id_01     id_02  id_03  id_04  id_05  id_06  id_07  id_08  \\\n",
       "0        2987004    0.0   70787.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1        2987008   -5.0   98945.0    NaN    NaN    0.0   -5.0    NaN    NaN   \n",
       "2        2987010   -5.0  191631.0    0.0    0.0    0.0    0.0    NaN    NaN   \n",
       "\n",
       "   id_09  ...                id_31  id_32      id_33           id_34  id_35  \\\n",
       "0    NaN  ...  samsung browser 6.2   32.0  2220x1080  match_status:2      T   \n",
       "1    NaN  ...   mobile safari 11.0   32.0   1334x750  match_status:1      T   \n",
       "2    0.0  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
       "\n",
       "  id_36 id_37  id_38  DeviceType                     DeviceInfo  \n",
       "0     F     T      T      mobile  SAMSUNG SM-G892A Build/NRD90M  \n",
       "1     F     F      T      mobile                     iOS Device  \n",
       "2     F     T      T     desktop                        Windows  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_identity.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_identity, train_transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enginnering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "# train['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "# train['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "# train['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "# test['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "# test['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "# test['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "# test['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "# train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "# train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "# train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "# train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "# test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "# test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "# test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "# test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "# train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "# train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "# train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "# train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "# test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "# test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "# test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "# test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "# train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "# train['D15_to_mean_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('mean')\n",
    "# train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "# train['D15_to_std_addr2'] = train['D15'] / train.groupby(['addr2'])['D15'].transform('std')\n",
    "\n",
    "# test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "# test['D15_to_mean_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('mean')\n",
    "# test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "# test['D15_to_std_addr2'] = test['D15'] / test.groupby(['addr2'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\n",
    "# train[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\n",
    "# test[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\n",
    "# test[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer]  (1 of 3) Processing functiontransformer-1, total=   0.0s\n",
      "[ColumnTransformer] . (2 of 3) Processing simpleimputer, total=   8.8s\n",
      "[ColumnTransformer]  (3 of 3) Processing functiontransformer-2, total=   0.8s\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['ProductCD','P_emaildomain','R_emaildomain',\n",
    "                'card1','card2','card3','card4','card5','card6',\n",
    "                'addr1','addr2',\n",
    "                'M1','M2','M3','M4','M5','M6','M7','M8','M9']\n",
    "\n",
    "one_value_cols = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "many_null_cols = [col for col in X.columns if X[col].isnull().sum() / X.shape[0] > 0.9]\n",
    "big_top_value_cols = [col for col in X.columns if X[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "cols_to_drop = list(set(many_null_cols + big_top_value_cols + one_value_cols + ['TransactionDT', 'TransactionID']))\n",
    "\n",
    "from utils.tranformers import drop_columns, factorize\n",
    "\n",
    "columns = list(set(X.columns) - set(cols_to_drop + categorical_features))\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (FunctionTransformer(drop_columns, validate=False), cols_to_drop),\n",
    "    (SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=0), columns),\n",
    "    (FunctionTransformer(factorize, validate=False), categorical_features),\n",
    "    remainder='passthrough',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X = transformer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(X.shape[1],))\n",
    "dense_1 = Dense(10, activation='relu')(inputs)\n",
    "dense_2 = Dense(10, activation='relu')(dense_1)\n",
    "outputs = Dense(1, activation='sigmoid')(dense_2)\n",
    "    \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.    0.    1.    1.    0.    0.    0.    0.    0.    1.    1.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.\n",
      "   13.    0.    0.    0.    1.    0.    0.    0.    1.    0.    0.    0.\n",
      "    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   19.\n",
      "    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    2.    0.   68.5   1.    0.    0.    0.    0.    1.    0.\n",
      "    1.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    1.    0.    0.    0.    0.    1.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    1.    1.    0.    0.    0.    0.    1.   13.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  117.    0.\n",
      "    0.    0.    0.    0.    0.    0.   14.    1.    0.    0.    0.    0.\n",
      "    0.    1.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.\n",
      "    0.    1.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.\n",
      "    1.    1.    1.    0.    0.  117.    0.    0.    0.    1.    0.    0.\n",
      "    0.    0.    0.    0.    1.    0.    1.    0.    0.    0.    0.    0.\n",
      "    0.    0.    1.    0.    1.    1.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.\n",
      "    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    1.    0.    1.    0.    0.    0.   13.    0.\n",
      "    0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    1.    0.    0.    0.    0.    1.    0.  117.    0.    1.\n",
      "    1.    0.    1.    0.   -1.   -1.    0.   -1.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.   -1.   -1.   -1. ]]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 472432 samples, validate on 118108 samples\n",
      "Epoch 1/10\n",
      "472432/472432 [==============================] - 11s 24us/step - loss: 0.5839 - acc: 0.9629 - val_loss: 0.1312 - val_acc: 0.9673\n",
      "Epoch 2/10\n",
      "472432/472432 [==============================] - 11s 23us/step - loss: 0.1666 - acc: 0.9675 - val_loss: 0.1231 - val_acc: 0.9679\n",
      "Epoch 3/10\n",
      "472432/472432 [==============================] - 11s 23us/step - loss: 0.1223 - acc: 0.9695 - val_loss: 0.1162 - val_acc: 0.9699\n",
      "Epoch 4/10\n",
      "472432/472432 [==============================] - 12s 25us/step - loss: 0.1172 - acc: 0.9705 - val_loss: 0.1143 - val_acc: 0.9702\n",
      "Epoch 5/10\n",
      "472432/472432 [==============================] - 12s 25us/step - loss: 0.1149 - acc: 0.9708 - val_loss: 0.1120 - val_acc: 0.9704\n",
      "Epoch 6/10\n",
      "472432/472432 [==============================] - 11s 24us/step - loss: 0.1131 - acc: 0.9710 - val_loss: 0.1111 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      "472432/472432 [==============================] - 11s 24us/step - loss: 0.1123 - acc: 0.9713 - val_loss: 0.1123 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      "472432/472432 [==============================] - 11s 24us/step - loss: 0.1116 - acc: 0.9713 - val_loss: 0.1106 - val_acc: 0.9708\n",
      "Epoch 9/10\n",
      "472432/472432 [==============================] - 11s 23us/step - loss: 0.1117 - acc: 0.9715 - val_loss: 0.1137 - val_acc: 0.9703\n",
      "Epoch 10/10\n",
      "472432/472432 [==============================] - 11s 24us/step - loss: 0.1109 - acc: 0.9717 - val_loss: 0.1140 - val_acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(X[:1,:])\n",
    "history = model.fit(\n",
    "    x=X, \n",
    "    y=y, \n",
    "    validation_split=0.2, \n",
    "    epochs=10, \n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(transformer, \"assets/data_transformer.joblib\")\n",
    "model.save(\"assets/fraud_prediction_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
